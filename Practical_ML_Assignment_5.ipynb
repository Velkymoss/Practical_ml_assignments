{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://communications.univie.ac.at/fileadmin/_processed_/csm_Uni_Logo_2016_2f47aacf37.jpg\" \n",
    "     alt=\"Logo Universität Wien\" \n",
    "     width=\"200\"/>\n",
    "\n",
    "# Practical Machine Learning for Natural Language Processing - 2023 SS  \n",
    "\n",
    "### Assigment 1 - Python for Poets  \n",
    "\n",
    "This assigment is an adaptation for Python of the original exercise [\"Unix for Poets\"](https://www.cs.upc.edu/~padro/Unixforpoets.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBR said Friday the global economic downturn so far has\n",
      "had\n",
      "little effect on its business but warned some projects on its books\n",
      "could be in jeopardy if the headwinds persist into next year.\n",
      "\n",
      "\"With the economic outlook remaining uncertain, it is possible\n",
      "that\n",
      "customers may cancel or delay projects that are under way,\" said\n",
      "William\n",
      "Utt, chief executive of the Houston-based engineering and\n",
      "construction\n",
      "giant and government contractor.\n",
      "\n",
      "He did not predict how much of the company's $15.3billion in\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "with open(\"c:/users/maxmo/Desktop/Python_Course/Data/txt/nyt_200811.txt\", \"r\") as f:\n",
    "    input_text = f.read()\n",
    "\n",
    "print(input_text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will solve the following exercises using **Pure Python**  \n",
    "### (only packages \"string\" and \"re\" are allowed).  \n",
    "\n",
    "1. Count words in a text  \n",
    "2. Sort a list of words in various ways  \n",
    "   • ascii order   \n",
    "   • \"rhyming\" order   \n",
    "3. Extract useful info for a dictionary  \n",
    "4. Compute ngram statistics  \n",
    "5. Make a Concordance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Count words in a text\n",
    "\n",
    "a. Output a list of words in the file along with their frequency counts (ignoring case).   \n",
    "a. Count how many unique words there are (ignoring case).    \n",
    "c. Check how common are all different sequences of vowels (e.g. the sequences \"ieu\" or just \"e\" in \"lieutenant\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limiting length of input text\n",
    "text = input_text[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'was')\n",
      "(2, 'some')\n",
      "(1, 'earnings')\n",
      "(1, 'offshore')\n",
      "(2, 'thirdquarter')\n",
      "(1, 'reevaluate')\n",
      "(1, 'crude')\n",
      "(1, 'ampamp')\n",
      "(1, 'broader')\n",
      "(2, 'financial')\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "# removing numbers from text\n",
    "text = re.sub(r'[0-9]', '', text)\n",
    "# making text lowercase\n",
    "text = text.lower()\n",
    "# splitting text into tokens\n",
    "tokens = text.split()\n",
    "# removing punctuation\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "tokens = [w.translate(table) for w in tokens]\n",
    "# removing empty tokens\n",
    "tokens = [token for token in tokens if token != '']\n",
    "# creating a token frequency dictionary\n",
    "token_frequency = {token: tokens.count(token) for token in set(tokens)}\n",
    "# creating list of tuples \n",
    "token_frequency = [(v, k) for k, v in token_frequency.items()]\n",
    "# printing out token frequencies\n",
    "for token in token_frequency[0:10]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b)\n",
    "# counting unique tokens\n",
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ai\n",
      "241 i\n",
      "222 a\n",
      "404 e\n",
      "212 o\n",
      "101 u\n",
      "10 oo\n",
      "25 ou\n",
      "3 eo\n",
      "22 ea\n",
      "8 ia\n",
      "9 ie\n",
      "11 ee\n",
      "25 io\n",
      "5 ua\n",
      "6 ui\n",
      "2 au\n",
      "3 ue\n",
      "6 oi\n",
      "3 ei\n",
      "2 oa\n"
     ]
    }
   ],
   "source": [
    "# c)\n",
    "# replacing all consonants with whitespaces\n",
    "vowels = [re.sub(r'[bcdfghjklmnpqrstvwxyz]', ' ', token) for token in tokens]\n",
    "# splitting the tokens to obtain all vowel sequences\n",
    "vowels = [vowel.split() for vowel in vowels]\n",
    "# creating a flat list\n",
    "vowels = [item for sublist in vowels for item in sublist]\n",
    "# creating a vowel sequence frequency dictionary\n",
    "vowels_freqency = {vowel : vowels.count(vowel) for vowel in vowels}\n",
    "# printing out vowel sequence frequencies\n",
    "for k, v in vowels_freqency.items():\n",
    "    print(v, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sorting and reversing lines of text\n",
    "\n",
    "a. Sort each line alphabetically (ignoring case).  \n",
    "b. Sort in numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  \n",
    "c. Alphabetically reverse sort (ignoring case).  \n",
    "d. Sort in reverse numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting list of tuples:\n",
    "https://sparkbyexamples.com/python/sort-list-of-tuples-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 'a'),\n",
       " (1, 'abroad'),\n",
       " (1, 'acquisition'),\n",
       " (1, 'affected'),\n",
       " (1, 'affirmative'),\n",
       " (2, 'after'),\n",
       " (1, 'airfields'),\n",
       " (1, 'alabased'),\n",
       " (2, 'already'),\n",
       " (2, 'also')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "sorted(token_frequency, key = lambda token: token[1])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'abroad'),\n",
       " (1, 'acquisition'),\n",
       " (1, 'affected'),\n",
       " (1, 'affirmative'),\n",
       " (1, 'airfields'),\n",
       " (1, 'alabased'),\n",
       " (1, 'among'),\n",
       " (1, 'ampamp'),\n",
       " (1, 'announced'),\n",
       " (1, 'any')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b)\n",
    "sorted(token_frequency, key = lambda token: (token[0], token[1]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'york'),\n",
       " (5, 'year'),\n",
       " (1, 'would'),\n",
       " (4, 'work'),\n",
       " (4, 'with'),\n",
       " (1, 'windows'),\n",
       " (1, 'wind'),\n",
       " (2, 'william'),\n",
       " (1, 'will'),\n",
       " (3, 'which')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c)\n",
    "sorted(token_frequency, key = lambda token: token[1], reverse = True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 'the'),\n",
       " (25, 'in'),\n",
       " (22, 'and'),\n",
       " (22, 'to'),\n",
       " (17, 'of'),\n",
       " (13, 'kbr'),\n",
       " (12, 'a'),\n",
       " (10, 'projects'),\n",
       " (10, 'said'),\n",
       " (10, 'that')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d)\n",
    "sorted(token_frequency, key = lambda token: (-token[0], token[1]))[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Computing basic statistics\n",
    "\n",
    "a. Find the 50 most common words  \n",
    "b. Find the words in the NYT that end in \"zz\"  \n",
    "c. Count the lines, the words, and the characters  \n",
    "d. How many all uppercase words are there in this NYT file?  \n",
    "e, How many 4-letter words?  \n",
    "f. How many different words are there with no vowels?  \n",
    "g. **tricky:** How many “1 syllable” words are there?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input_text[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 'the'),\n",
       " (25, 'in'),\n",
       " (22, 'and'),\n",
       " (22, 'to'),\n",
       " (17, 'of'),\n",
       " (13, 'kbr'),\n",
       " (12, 'a'),\n",
       " (10, 'projects'),\n",
       " (10, 'said'),\n",
       " (10, 'that'),\n",
       " (7, 'its'),\n",
       " (7, 'on'),\n",
       " (6, 'but'),\n",
       " (6, 'cents'),\n",
       " (6, 'could'),\n",
       " (6, 'from'),\n",
       " (6, 'utt'),\n",
       " (5, 'are'),\n",
       " (5, 'be'),\n",
       " (5, 'business'),\n",
       " (5, 'customers'),\n",
       " (5, 'has'),\n",
       " (5, 'is'),\n",
       " (5, 'it'),\n",
       " (5, 'or'),\n",
       " (5, 'year'),\n",
       " (4, 'construction'),\n",
       " (4, 'economic'),\n",
       " (4, 'engineering'),\n",
       " (4, 'for'),\n",
       " (4, 'have'),\n",
       " (4, 'he'),\n",
       " (4, 'if'),\n",
       " (4, 'into'),\n",
       " (4, 'more'),\n",
       " (4, 'much'),\n",
       " (4, 'new'),\n",
       " (4, 'next'),\n",
       " (4, 'oil'),\n",
       " (4, 'percent'),\n",
       " (4, 'share'),\n",
       " (4, 'so'),\n",
       " (4, 'with'),\n",
       " (4, 'work'),\n",
       " (3, 'been'),\n",
       " (3, 'billion'),\n",
       " (3, 'building'),\n",
       " (3, 'companys'),\n",
       " (3, 'costs'),\n",
       " (3, 'delay')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "sorted(token_frequency, key = lambda token: (-token[0], token[1]))[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b)\n",
    "re.findall(r'\\S+zz\\b', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines: 159\n",
      "words: 788\n",
      "characters: 5000\n"
     ]
    }
   ],
   "source": [
    "# c)\n",
    "# counting all line breaks + 1 for the starting line\n",
    "lines = len(re.findall(r'\\n', text)) + 1\n",
    "# counting all words including counting words with \"'\" and \"-\" in it as one word\n",
    "words = len(re.findall(f'[A-Za-z\\'-]+', text))\n",
    "# printing out the counts of lines, words and characters\n",
    "print(f'lines: {lines}\\nwords: {words}\\ncharacters: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d)\n",
    "len(re.findall(r'\\b[A-Z]{2,}\\b', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e)\n",
    "len(re.findall(r'\\b[a-zA-Z]{4}\\b', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f) \n",
    "len(set(re.findall(r'\\b[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]{2,}\\b', text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are approximately 284 words with one syllable in the text.\n"
     ]
    }
   ],
   "source": [
    "# g)\n",
    "def syllable_counter(word):\n",
    "    \"\"\"function for counting syllables of a word\"\"\"\n",
    "    # set counter to 0\n",
    "    counter = 0\n",
    "    # Input word to an array of characters\n",
    "    letters = [letter for letter in word]\n",
    "    # comparing two consecutive characters in the word\n",
    "    for i in range(0, (len(letters)-2)):\n",
    "        # new syllable when pair of characters is a vowel fallowed by a consonant\n",
    "        if letters[i] in 'aeiou' and letters[i+1] not in 'aeiou':\n",
    "            counter += 1\n",
    "    # new syllable if last character is a vowel\n",
    "    if letters[(len(letters)-1)] in 'aiouy':\n",
    "        counter += 1\n",
    "    return counter\n",
    "\n",
    "one_syllables = 0\n",
    "for token in tokens:\n",
    "    if syllable_counter(token) == 1:\n",
    "        one_syllables += 1\n",
    "print(f'There are approximately {one_syllables} words with one syllable in the text.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compute ngrams  \n",
    "\n",
    "a. Find the 10 most common bigrams  \n",
    "b. Find the 10 most common trigrams  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "def bigramise(token_list):\n",
    "    \"\"\"function to find all bigrams of a text\"\"\"\n",
    "    bigrams = []\n",
    "    for i in range(0, (len(token_list)-1)):\n",
    "        bigram = f'{token_list[i]} {token_list[i+1]}'\n",
    "        bigrams.append(bigram)\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 'in the'),\n",
       " (5, 'of the'),\n",
       " (4, 'next year'),\n",
       " (4, 'on its'),\n",
       " (3, 'and construction'),\n",
       " (3, 'cents per'),\n",
       " (3, 'could be'),\n",
       " (3, 'engineering and'),\n",
       " (3, 'if the'),\n",
       " (3, 'per share')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = bigramise(tokens)\n",
    "# creating bigrams_frequency dictionary\n",
    "bigrams_freqency = {bigram : bigrams.count(bigram) for bigram in bigrams}\n",
    "# creating list of tuples of bigram frequencies in reverse numeric order\n",
    "bigrams_frequency = [(v, k) for k, v in bigrams_freqency.items()]\n",
    "bigrams_frequency = sorted(bigrams_frequency, key = lambda token: (-token[0], token[1]))\n",
    "# 10 most common bigrams\n",
    "bigrams_frequency[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n",
    "def trigramise(token_list):\n",
    "    \"\"\"function to find all trigrams of a text\"\"\"\n",
    "    trigrams = []\n",
    "    for i in range(0, (len(token_list)-2)):\n",
    "        trigram = f'{token_list[i]} {token_list[i+1]} {token_list[i+2]}'\n",
    "        trigrams.append(trigram)\n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'cents per share'),\n",
       " (3, 'engineering and construction'),\n",
       " (2, 'and construction giant'),\n",
       " (2, 'are under way'),\n",
       " (2, 'be in jeopardy'),\n",
       " (2, 'books could be'),\n",
       " (2, 'business but warned'),\n",
       " (2, 'but warned some'),\n",
       " (2, 'cancel or delay'),\n",
       " (2, 'chief executive of')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = trigramise(tokens)\n",
    "# creating trigrams_frequency dictionary\n",
    "trigrams_freqency = {trigram : trigrams.count(trigram) for trigram in trigrams}\n",
    "# creating list of tuples of trigram frequencies in reverse numeric order\n",
    "trigrams_frequency = [(v, k) for k, v in trigrams_freqency.items()]\n",
    "trigrams_frequency = sorted(trigrams_frequency, key = lambda token: (-token[0], token[1]))\n",
    "# 10 most common bigrams\n",
    "trigrams_frequency[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Make a Concordance\n",
    "\n",
    "a. Create a concordance display for an arbitrary word. See the example below  \n",
    "\n",
    "![](../../Data/figs/Sample-concordance-lines-of-actually.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "def concordance(word, text_to_search, number_context_words):\n",
    "    \"\"\"function to create a concordance for an input word\"\"\"\n",
    "    if word not in text_to_search:\n",
    "        return f'Error: Input word \"{word}\" not found in input text'\n",
    "    else:\n",
    "        tokens = text_to_search.split()\n",
    "        num = number_context_words \n",
    "        concordance_list = []\n",
    "\n",
    "        word_indices  = [index for (index, item) in enumerate(tokens) if item == word]\n",
    "\n",
    "        for i in word_indices:\n",
    "            concordance_line = []\n",
    "            if i < num:\n",
    "                concordance_line.append(' '.join(tokens[0:i]))\n",
    "                concordance_line.append(word)\n",
    "                concordance_line.append(' '.join(tokens[i+1:i+num+1]))\n",
    "                concordance_list.append(concordance_line)\n",
    "            else:\n",
    "                concordance_line.append(' '.join(tokens[i-num:i]))\n",
    "                concordance_line.append(word)\n",
    "                concordance_line.append(' '.join(tokens[i+1:i+num+1]))\n",
    "                concordance_list.append(concordance_line)\n",
    "\n",
    "        return concordance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KBR said Friday the global --- economic --- downturn so far has had little effect on its business\n",
      "\n",
      "2 jeopardy if the headwinds persist into next year. \"With the --- economic --- outlook remaining uncertain, it is possible that customers may cancel\n",
      "\n",
      "3 in the Gulf of Mexico. KBR said Friday the global --- economic --- downturn so far has had little effect on its business\n",
      "\n",
      "4 jeopardy if the headwinds persist into next year. \"With the --- economic --- outlook remaining uncertain, it is possible that customers may cancel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "occurance = 1\n",
    "for line in concordance('economic', text, 10):\n",
    "    print(f'{occurance} {line[0]} --- {line[1]} --- {line[2]}\\n')\n",
    "    occurance += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit – Secret Message\n",
    "+ The answers to the extra credit exercises will reveal a secret message.  \n",
    "+ We will be working with the following text file for these exercises:  \n",
    "[Link to Text](https://web.stanford.edu/class/cs124/lec/secret_ec.txt)  \n",
    "(No starter code in the Extra Credit)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 1\n",
    "• Find the 2 most common words in secret_ec.txt containing the letter e.  \n",
    "• Your answer will correspond to the first two words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 2\n",
    "• Find the 2 most common bigrams in secret_ec.txt where the second word in the bigram ends with a consonant.  \n",
    "• Your answer will correspond to the next four words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 3\n",
    "• Find all 5-letter-long words that only appear once in secret_ec.txt.   \n",
    "• Concatenate your result. This will be the final word of the secret message.  \n",
    "\n",
    "What is the secret message?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
